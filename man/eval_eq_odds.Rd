% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Fairness.R
\name{eval_eq_odds}
\alias{eval_eq_odds}
\title{Examine Equalized Odds of a Predictive Model}
\usage{
eval_eq_odds(
  data,
  outcome,
  group,
  probs,
  cutoff = 0.5,
  bootstraps = 2500,
  alpha = 0.05,
  digits = 2,
  message = TRUE
)
}
\arguments{
\item{data}{A dataframe containing the actual outcomes, predicted outcomes,
and sensitive attributes necessary for evaluating model fairness.}

\item{outcome}{The name of the outcome variable in the data; it must be binary.}

\item{group}{The name of the sensitive attribute variable used to define groups
for comparison in the fairness evaluation.}

\item{probs}{The name of the variable containing predicted probabilities or scores.}

\item{cutoff}{The threshold for converting predicted probabilities into binary
predictions; defaults to 0.5.}

\item{bootstraps}{The number of bootstrap samples used for estimating the
uncertainty in the fairness metrics; defaults to 1000.}

\item{alpha}{The 1 - significance level for the confidence interval; defaults to 0.05.}

\item{digits}{The number of decimal places to which numerical results are rounded;
defaults to 2.}

\item{message}{Logical; whether to print summary results to the console; defaults to TRUE.}
}
\value{
Returns a dataframe with the following columns:
\itemize{
\item Metric: Describes the metric being reported (FNR and FPR for each group, difference).
\item Group1: Rate for the first group.
\item Group2: Rate for the second group.
\item Difference: The difference in rates between the two groups.
\item 95\% Difference CI: The 95\% confidence interval for the rate difference.
\item Ratio: The ratio in False Negative Rates between the two groups.
\item 95\% Ratio CI: The 95\% confidence interval for the FNR ratio
}
}
\description{
This function examines the equalized odds of a predictive model by comparing
both the False Negative Rates (FNR) and False Positive Rates (FPR) across different
groups defined by a sensitive attribute. It assesses if a model performs unbiasedly
for binary outcomes across these groups, adhering to the equalized odds fairness criterion.
}
\examples{
\donttest{
library(FairnessTutorial)
library(dplyr)
library(randomForest)
data("mimic_preprocessed")
set.seed(123)
train_data <- mimic_preprocessed |>
  dplyr::filter(dplyr::row_number() <= 700)
# Fit a random forest model
rf_model <- randomForest::randomForest(factor(day_28_flg) ~ ., data = train_data, ntree = 1000)
# Test the model on the remaining data
test_data <- mimic_preprocessed |>
  dplyr::mutate(gender = ifelse(gender_num == 1, "Male", "Female"))|>
  dplyr::filter(dplyr::row_number() > 700)

test_data$pred <- predict(rf_model, newdata = test_data, type = "prob")[, 2]

# Fairness evaluation
# We will use sex as the sensitive attribute and day_28_flg as the outcome.
# We choose threshold = 0.41 so that the overall FPR is around 5\%.

# Evaluate Equalized Odds
eval_eq_odds(
  dat = test_data,
  outcome = "day_28_flg",
  group = "gender",
  probs = "pred",
  cutoff = 0.41
)
}
}
