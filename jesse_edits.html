<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Summary • fairmetrics</title><script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Summary"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">fairmetrics</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="articles/fairmetrics.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json"></form></li>
      </ul></div>


  </div>
</nav><div class="container template-title-body">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Summary</h1>

    </div>


<div id="summary" class="section level1">

<div class="section level2">
<h2 id="rewritten">Rewritten<a class="anchor" aria-label="anchor" href="#rewritten"></a></h2>
<p>Fairness is a growing area of machine learning (ML) that focuses on ensuring models do not produce systematically biased outcomes for certain groups, particularly those defined by protected attributes such as race, gender, or age. Evaluating fairness is a critical aspect of model development, as biased models can perpetuate or exacerbate existing social inequalities. The {fairmetrics} R package offers a user-friendly framework for rigorously evaluating numerous group-based fairness criteria, including metrics based on independence (e.g., statistical parity), separation (e.g., equalized odds), and sufficiency (e.g., predictive parity). These criteria assess whether a model is equally accurate or well-calibrated across predefined groups so that appropriate bias mitigation strategies can be implemented. {fairmetrics} provides both point and interval estimates for multiple metrics through convenient wrapper functions, and includes example an dataset derived from the Medical Information Mart for Intensive Care, version II (MIMIC-II) database [@goldberger2000physiobank; @raffa2016clinical].</p>
</div>
</div>
<div class="section level1">
<h1 id="statement-of-need">Statement of Need<a class="anchor" aria-label="anchor" href="#statement-of-need"></a></h1>
<div class="section level2">
<h2 id="jianhui---this-is-too-similar-to-the-original-paper-still-and-i-suggest-we-emphasize-that-the-package-isnt-restricted-to-biomedical-data-we-can-of-course-use-it-as-an-example-but-this-isnt-the-need-for-the-package-can-you-rewrite-this-to-just-be-about-the-general-use-of-fairness-ie-point-1---ml-increasing-integrated-into-different-areas-point-2---give-a-few-examples-point-3---need-for-the-package-in-light-of-other-work-i-dont-think-interpetable-is-the-correct-word-here-the-key-difference-is-allowing-for-uncertainty-quantification-we-also-provide-ratio--difference-estimates-i-dont-think-r-fairness-package-does-i-would-emphasize">Jianhui - this is too similar to the original paper still and I suggest we emphasize that the package isn’t restricted to biomedical data. We can of course use it as an example but this isn’t the need for the package. Can you rewrite this to just be about the general use of fairness? i.e., point 1 - ml increasing integrated into different areas, point 2 - give a few examples, point 3 - need for the package in light of other work. I don’t think interpetable is the correct word here, the key difference is allowing for uncertainty quantification, we also provide ratio + difference estimates, i dont think R fairness package does, I would emphasize<a class="anchor" aria-label="anchor" href="#jianhui---this-is-too-similar-to-the-original-paper-still-and-i-suggest-we-emphasize-that-the-package-isnt-restricted-to-biomedical-data-we-can-of-course-use-it-as-an-example-but-this-isnt-the-need-for-the-package-can-you-rewrite-this-to-just-be-about-the-general-use-of-fairness-ie-point-1---ml-increasing-integrated-into-different-areas-point-2---give-a-few-examples-point-3---need-for-the-package-in-light-of-other-work-i-dont-think-interpetable-is-the-correct-word-here-the-key-difference-is-allowing-for-uncertainty-quantification-we-also-provide-ratio--difference-estimates-i-dont-think-r-fairness-package-does-i-would-emphasize"></a></h2>
</div>
</div>
<div class="section level1">
<h1 id="these-are-other-r-packages-i-am-aware-of-so-need-to-cite--compare-httpsmlr3fairnessmlr-orgcom-httpscranr-projectorgwebpackagesfairnessvignettesfairnesshtml">These are other R packages I am aware of so need to cite + compare: <a href="https://mlr3fairness.mlr-org.com" class="external-link uri">https://mlr3fairness.mlr-org.com</a>, <a href="https://cran.r-project.org/web/packages/fairness/vignettes/fairness.html" class="external-link uri">https://cran.r-project.org/web/packages/fairness/vignettes/fairness.html</a>
<a class="anchor" aria-label="anchor" href="#these-are-other-r-packages-i-am-aware-of-so-need-to-cite--compare-httpsmlr3fairnessmlr-orgcom-httpscranr-projectorgwebpackagesfairnessvignettesfairnesshtml"></a></h1>
<p>Machine learning (ML) offers significant potential for predictive modelling in biomedical research [@rajpurkarAIHealthMedicine2022]. Despite its promise, there is substantial evidence that, without appropriate forethought and planning, ML models can introduce or exacerbate health inequities by making less accurate decisions for certain groups or individuals [@grote2022enabling]. While existing software can compute fairness metrics, none provide out-of-the-box statistical inference, leaving practitioners without guidance on the uncertainty around those metrics. As ML becomes increasingly embedded in healthcare systems, ensuring equitable model performance across diverse populations is essential[@Gao_Chou_McCaw_Thurston_Varghese_Hong_Gronsbell_2024]. The {fairmetrics} R package fills this gap by offering a suite of popular group-fairness metrics along with bootstrap-based confidence intervals, enabling more rigorous and interpretable assessments of fairness in biomedical ML.</p>
</div>
<div class="section level1">
<h1 id="fairness-criteria">Fairness Criteria<a class="anchor" aria-label="anchor" href="#fairness-criteria"></a></h1>
<div class="section level2">
<h2 id="both---deleted-first-paragaph-as-it-is-not-relevant-to-your-package-also-restructured">Both - Deleted first paragaph as it is not relevant to your package. Also restructured.<a class="anchor" aria-label="anchor" href="#both---deleted-first-paragaph-as-it-is-not-relevant-to-your-package-also-restructured"></a></h2>
</div>
<div class="section level2">
<h2 id="this-section-needs-to-be-cleaned-up-for-clarity---see-comments-below">This section needs to be cleaned up for clarity - see comments below.<a class="anchor" aria-label="anchor" href="#this-section-needs-to-be-cleaned-up-for-clarity---see-comments-below"></a></h2>
<p>Group fairness criteria are typically classified into three main categories: independence, separation, and sufficiency [@barocas2023fairness; @Berk_Heidari_Jabbari_Kearns_Roth_2018; @Castelnovo_Crupi_Greco_Regoli_Penco_Cosentini_2022]. The {fairmetrics} package computes a range of group fairness metrics together with bootstrap-based confidence intervals for uncertainty quantification. The metrics implemented in the package are briefly described below.</p>
</div>
<div class="section level2">
<h2 id="jianhui---the-scope-of-the-package-is-not-defined-in-the-above-paragprah-so-one-would-not-understand-the-definitons-below-ie-positive-classification-is-never-defined-specifically-you-need-to-say-you-consider-binary-classification-and-a-binary-protected-attribute---i-do-not-believe-your-package-handles-more-than-explain-why-this-is-done-and-then-update-the-definitions-below-to-reflect-this">Jianhui - The scope of the package is not defined in the above paragprah so one would not understand the definitons below (i.e., “positive classification” is never defined). Specifically, you need to say you consider binary classification and a binary protected attribute - I do not believe your package handles more than. Explain why this is done and then update the definitions below to reflect this.<a class="anchor" aria-label="anchor" href="#jianhui---the-scope-of-the-package-is-not-defined-in-the-above-paragprah-so-one-would-not-understand-the-definitons-below-ie-positive-classification-is-never-defined-specifically-you-need-to-say-you-consider-binary-classification-and-a-binary-protected-attribute---i-do-not-believe-your-package-handles-more-than-explain-why-this-is-done-and-then-update-the-definitions-below-to-reflect-this"></a></h2>
</div>
<div class="section level2">
<h2 id="jianhui---why-do-you-use-bootstrap-for-this-package-rather-than-if-is-it-because-you-dont-have-if-for-all-metrics">Jianhui - why do you use bootstrap for this package rather than IF? Is it because you don’t have IF for all metrics?<a class="anchor" aria-label="anchor" href="#jianhui---why-do-you-use-bootstrap-for-this-package-rather-than-if-is-it-because-you-dont-have-if-for-all-metrics"></a></h2>
</div>
<div class="section level2">
<h2 id="jianhui---please-update-the-initial-sentences-describing-the-3-categories-to-be-more-intuitive-akin-to-what-we-have-in-the-paper">Jianhui - please update the initial sentences describing the 3 categories to be more intuitive, akin to what we have in the paper.<a class="anchor" aria-label="anchor" href="#jianhui---please-update-the-initial-sentences-describing-the-3-categories-to-be-more-intuitive-akin-to-what-we-have-in-the-paper"></a></h2>
</div>
<div class="section level2">
<h2 id="independence">Independence<a class="anchor" aria-label="anchor" href="#independence"></a></h2>
<p>Independence requires that an ML model’s predictions be statistically independent of the protected attribute.</p>
<ul><li><p><strong>Statistical Parity:</strong> Compares the overall rate of positive predictions between groups, irrespective of the true outcome.</p></li>
<li><p><strong>Conditional Statistical Parity:</strong> Restricts the comparison of positive prediction rates to a specific subgroup (e.g., within a hospital unit or age bracket), offering a more context-specific fairness assessment.</p></li>
</ul></div>
<div class="section level2">
<h2 id="use-consistent-language-throughout---alternating-between-checkscomparesfocusesassessmeasureetc-is-confusing-as-all-functions-do-the-same-thing-suggest-use-compares-for-all">Use consistent language throughout - alternating between checks/compares/focuses/assess/measure/etc is confusing as all functions do the same thing. Suggest use “Compares” for all.<a class="anchor" aria-label="anchor" href="#use-consistent-language-throughout---alternating-between-checkscomparesfocusesassessmeasureetc-is-confusing-as-all-functions-do-the-same-thing-suggest-use-compares-for-all"></a></h2>
</div>
<div class="section level2">
<h2 id="separation">Separation<a class="anchor" aria-label="anchor" href="#separation"></a></h2>
<p>Separation demands that the model’s predictions be independent of the protected attribute conditional on the true outcome class (i.e., within the positive and negative classes).</p>
<ul><li>
<strong>Equal Opportunity:</strong> Focuses on disparities in false negative rates (FNR) between two groups, quantifying any difference in missed positive cases.</li>
</ul></div>
<div class="section level2">
<h2 id="do-you-need-the-acronyms-for-fnr-and-fpr-if-you-dont-use-them-later-they-dont-need-to-be-defined">Do you need the acronyms for FNR and FPR? If you don’t use them later, they don’t need to be defined.<a class="anchor" aria-label="anchor" href="#do-you-need-the-acronyms-for-fnr-and-fpr-if-you-dont-use-them-later-they-dont-need-to-be-defined"></a></h2>
<ul><li><p><strong>Predictive Equality:</strong> Compares false positive rates (FPR) between groups, ensuring that no group is disproportionately flagged as positive when the true outcome is negative.</p></li>
<li><p><strong>Positive Class Balance:</strong> Checks whether, among individuals whose true outcome is positive, the distribution of predicted probabilities is comparable across groups.</p></li>
<li><p><strong>Negative Class Balance:</strong> Checks whether, among individuals whose true outcome is negative, the distribution of predicted probabilities is comparable across groups.</p></li>
</ul></div>
<div class="section level2">
<h2 id="sufficiency">Sufficiency<a class="anchor" aria-label="anchor" href="#sufficiency"></a></h2>
<p>Sufficiency requires that, given a model’s prediction, the likelihood of the true outcome is independent of the protected attribute—aiming to equalize error rates across groups for similar prediction score.</p>
<ul><li>
<strong>Predictive Parity:</strong> Compares positive predictive values (PPV) across groups, assessing whether the precision of positive predictions is equivalent.</li>
</ul></div>
<div class="section level2">
<h2 id="other-criteria">Other Criteria<a class="anchor" aria-label="anchor" href="#other-criteria"></a></h2>
<ul><li><p><strong>Brier Score Parity:</strong> Assesses whether the Brier score—the mean squared error of probabilistic predictions—is similar across groups, indicating comparable calibration.</p></li>
<li><p><strong>Accuracy Parity:</strong> Measures whether the overall accuracy of a predictive model is equivalent across different groups.</p></li>
<li><p><strong>Treatment Equality:</strong> Compares the ratio of false negatives to false positives across groups, ensuring the balance of missed detections versus false alarms is consistent.</p></li>
</ul></div>
</div>
<div class="section level1">
<h1 id="evaluating-fairness-criteria">Evaluating Fairness Criteria<a class="anchor" aria-label="anchor" href="#evaluating-fairness-criteria"></a></h1>
<div class="section level2">
<h2 id="rewritten-1">Rewritten<a class="anchor" aria-label="anchor" href="#rewritten-1"></a></h2>
</div>
<div class="section level2">
<h2 id="ben---the-package-doesnt-require-data-splitting-some-people-may-want-to-use-the-package-and-incorporate-cv-within-training-also-sometimes-people-evaluate-fairness-metrics-on-validation-data-so-suggest-you-simplify-text--figure-just-start-with-the-input-also-it-doesnt-seem-like-multiple-should-be-a-separate-node-doesnt-it-just-include-all-the-4-boxes-sep-suff-ind-other-can-this-be-depicted-also-suggest-you-make-the-names-more-descriptive-separation-based-metrics-independence-based-metrics-etc">Ben - The package doesn’t require data splitting, some people may want to use the package and incorporate CV within training. Also, sometimes people evaluate fairness metrics on validation data. So suggest you simplify text + figure. Just start with the input. Also, it doesn’t seem like multiple should be a separate node? doesnt it just include all the 4 boxes (sep, suff, ind, other)? can this be depicted? Also suggest you make the names more descriptive “Separation-based Metrics”, “Independence-based Metrics”, etc.<a class="anchor" aria-label="anchor" href="#ben---the-package-doesnt-require-data-splitting-some-people-may-want-to-use-the-package-and-incorporate-cv-within-training-also-sometimes-people-evaluate-fairness-metrics-on-validation-data-so-suggest-you-simplify-text--figure-just-start-with-the-input-also-it-doesnt-seem-like-multiple-should-be-a-separate-node-doesnt-it-just-include-all-the-4-boxes-sep-suff-ind-other-can-this-be-depicted-also-suggest-you-make-the-names-more-descriptive-separation-based-metrics-independence-based-metrics-etc"></a></h2>
<p>The input to the {fairmetrics} package is a data frame or tibble which containing the model’s predictions, true outcomes, and the protected attributes (attribute? doesn’t package only handle 1?).  shows the workflow for using {fairmetrics}. It is possible to evaluate a model for a specific or multiple group fairness metrics.</p>
<p><img src="fairmetrics-workflow.png" alt="Workflow for using {fairmetrics} to evaluate model fairness across multiple criteria. "> ## Edited A simple example of how to use the {fairmetrics} package is shown below. The example uses the <code>mimic_preprocessed</code> dataset, which is a pre-processed version of the MIMIC-II database [@goldberger2000physiobank; @raffa2016clinical].</p>
</div>
<div class="section level2">
<h2 id="ben---need-to-add-detail-on-what-the-detail-is-in-the-above-paragraph-what-does-the-data-contaon-where-did-it-come-from-what-is-the-sample-size-etc">Ben - need to add detail on what the detail is in the above paragraph. What does the data contaon, where did it come from, what is the sample size, etc.<a class="anchor" aria-label="anchor" href="#ben---need-to-add-detail-on-what-the-detail-is-in-the-above-paragraph-what-does-the-data-contaon-where-did-it-come-from-what-is-the-sample-size-etc"></a></h2>
</div>
<div class="section level2">
<h2 id="ben---suggest-you-show-more-of-the-functions-in-the-package---say-that-while-the-choice-of-metric-is-context-dependent-we-show-all-metrics-to-show-the-full-range-of-the-package-also-include-interpretation-of-the-various-results-simple-way-to-do-this-is-show-the-multiple-output-then-show-an-example-of-one-of-the-separation-based-criterion-or-other-to-show-users-they-can-specify-what-they-want">Ben - suggest you show more of the functions in the package - say that, while the choice of metric is context dependent, we show all metrics to show the full range of the package. Also include interpretation of the various results. Simple way to do this is show, the multiple output then show an example of one of the separation-based criterion or other to show users they can specify what they want.<a class="anchor" aria-label="anchor" href="#ben---suggest-you-show-more-of-the-functions-in-the-package---say-that-while-the-choice-of-metric-is-context-dependent-we-show-all-metrics-to-show-the-full-range-of-the-package-also-include-interpretation-of-the-various-results-simple-way-to-do-this-is-show-the-multiple-output-then-show-an-example-of-one-of-the-separation-based-criterion-or-other-to-show-users-they-can-specify-what-they-want"></a></h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://jianhuig.github.io/fairmetrics/" class="external-link">fairmetrics</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://magrittr.tidyverse.org" class="external-link">magrittr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://www.stat.berkeley.edu/~breiman/RandomForests/" class="external-link">randomForest</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Load the example dataset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"mimic_preprocessed"</span><span class="op">)</span>  </span>
<span></span>
<span><span class="co"># Split the data into training and test sets</span></span>
<span><span class="va">train_data</span> <span class="op">&lt;-</span> <span class="va">mimic_preprocessed</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/row_number.html" class="external-link">row_number</a></span><span class="op">(</span><span class="op">)</span> <span class="op">&lt;=</span> <span class="fl">700</span><span class="op">)</span></span>
<span></span>
<span><span class="va">test_data</span> <span class="op">&lt;-</span> <span class="va">mimic_preprocessed</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>gender <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">gender_num</span> <span class="op">==</span> <span class="fl">1</span>, <span class="st">"Male"</span>, <span class="st">"Female"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/row_number.html" class="external-link">row_number</a></span><span class="op">(</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">700</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Train a random forest model</span></span>
<span><span class="va">rf_model</span> <span class="op">&lt;-</span> <span class="fu">randomForest</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html" class="external-link">randomForest</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">day_28_flg</span><span class="op">)</span> <span class="op">~</span> <span class="va">.</span>, </span>
<span>  data <span class="op">=</span> <span class="va">train_data</span>, </span>
<span>  ntree <span class="op">=</span> <span class="fl">1000</span></span>
<span>  <span class="op">)</span></span>
<span>  </span>
<span><span class="co"># Make predictions on the test set</span></span>
<span><span class="va">test_data</span><span class="op">$</span><span class="va">pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">rf_model</span>, newdata <span class="op">=</span> <span class="va">test_data</span>, type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Evaluate predictive equality</span></span>
<span><span class="co"># (Setting message=FALSE to avoid cluttering the output)</span></span>
<span></span>
<span><span class="fu"><a href="reference/eval_pred_equality.html">eval_pred_equality</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">test_data</span>,</span>
<span>  outcome <span class="op">=</span> <span class="st">"day_28_flg"</span>,</span>
<span>  group <span class="op">=</span> <span class="st">"gender"</span>,</span>
<span>  probs <span class="op">=</span> <span class="st">"pred"</span>,</span>
<span>  cutoff <span class="op">=</span> <span class="fl">0.41</span>,</span>
<span>  message <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co">#&gt;   Metric GroupFemale GroupMale Difference  95% Diff CI Ratio 95% Ratio CI</span></span>
<span><span class="co">#&gt; 1    FPR        0.08      0.03       0.05 [0.02, 0.08]  2.67 [1.38, 5.15]</span></span></code></pre></div>
<p>This case it can be seen from both the difference and ratio of the false positive rates (FPR) that the model is biased, with a 2.67 times higher chance of a false positive prediction for heart failure for females compared to males. The 95% bootstrap confidence intervals for both the difference and the ratio of the FPR are also shown, which can be used to further assess the statistical significance of the difference, confirming the initial evaluation of the FPR for female and male patients.</p>
</div>
</div>
<div class="section level1">
<h1 id="related-work">Related Work<a class="anchor" aria-label="anchor" href="#related-work"></a></h1>
<div class="section level2">
<h2 id="both---you-are-missing-this-one-httpsmlr3fairnessmlr-orgcom">Both - you are missing this one: <a href="https://mlr3fairness.mlr-org.com" class="external-link uri">https://mlr3fairness.mlr-org.com</a>
<a class="anchor" aria-label="anchor" href="#both---you-are-missing-this-one-httpsmlr3fairnessmlr-orgcom"></a></h2>
</div>
<div class="section level2">
<h2 id="do-these-metrics-give-difference-and-ratio-based-criteria-are-there-any-other-differences">Do these metrics give difference and ratio based criteria? Are there any other differences?<a class="anchor" aria-label="anchor" href="#do-these-metrics-give-difference-and-ratio-based-criteria-are-there-any-other-differences"></a></h2>
<p>Other R packages similar to {fairmetrics} include {fairness}[@fairness_package] and {fairmodels} [@wisniewski2022fairmodels]. The differences between {fairmetrics} and these other packages is twofold. The primary difference between is that {fairmetrics} allows for the calculation of estimated confidence intervals of fairness metrics via bootstrap, which allows for more meaningful inferences about the fairness metrics calculated. Additionally, in contrast to the {fairmodels} and {fairness} packages, the {fairmetrics} package has zero library dependencies and a lower memory footprint, resulting in an environment agnostic tool that can be used with modest hardware and older systems.  shows the comparison of memory used and dependencies required when loading each library.</p>
<p>For python users, the {fairlearn} library [@fairlearn_paper] provides a broader set of fairness metrics and algorithms. The {fairmetrics} package is designed for seemless integration with R workflows, making it a more convenient choice for R-based ML applications.</p>
</div>
</div>
<div class="section level1">
<h1 id="licensing-and-availability">Licensing and Availability<a class="anchor" aria-label="anchor" href="#licensing-and-availability"></a></h1>
<p>The {fairmetrics} package is under the MIT license. It is available on CRAN and can be installed by using <code>install.packages("fairmetrics")</code>. A more in-depth tutorial can be accessed at: <a href="https://jianhuig.github.io/fairmetrics/articles/fairmetrics.html" class="external-link uri">https://jianhuig.github.io/fairmetrics/articles/fairmetrics.html</a>. All code is open-source and hosted on GitHub. All bugs and inquiries can be reported at <a href="https://github.com/jianhuig/fairmetrics/issues/" class="external-link uri">https://github.com/jianhuig/fairmetrics/issues/</a>.</p>
</div>
<div class="section level1">
<h1 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h1>
</div>


  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Jianhui Gao, Benjamin Smith, Benson Chou, Jessica Gronsbell.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

