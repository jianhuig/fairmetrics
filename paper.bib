@article{rajpurkarAIHealthMedicine2022,
	title = {{AI} in health and medicine},
	volume = {28},
	issn = {1546-170X},
	url = {https://doi.org/10.1038/s41591-021-01614-0},
	doi = {10.1038/s41591-021-01614-0},
	abstract = {Artificial intelligence (AI) is poised to broadly reshape medicine, potentially improving the experiences of both clinicians and patients. We discuss key findings from a 2-year weekly effort to track and share key developments in medical AI. We cover prospective studies and advances in medical image analysis, which have reduced the gap between research and deployment. We also address several promising avenues for novel medical AI research, including non-image data sources, unconventional problem formulations and human–AI collaboration. Finally, we consider serious technical and ethical challenges in issues spanning from data scarcity to racial bias. As these challenges are addressed, AI’s potential may be realized, making healthcare more accurate, efficient and accessible for patients worldwide.},
	number = {1},
	journal = {Nature Medicine},
	author = {Rajpurkar, Pranav and Chen, Emma and Banerjee, Oishi and Topol, Eric J.},
	month = jan,
	year = {2022},
	pages = {31--38},
}

@article{grote2022enabling,
  title={Enabling Fairness in Healthcare Through Machine Learning},
  author={Grote, Thomas and Keeling, Geoff},
  journal={Ethics and Information Technology},
  volume={24},
  number={3},
  pages={39},
  year={2022},
  publisher={Springer},
  doi={10.1007/s10676-022-09658-7},
  pmid={36060496},
  pmcid={PMC9428374},
  url={https://pmc.ncbi.nlm.nih.gov/articles/PMC9428374/}
}

@article{Ueda_Kakinuma_Fujita_Kamagata_Fushimi_Ito_Matsui_Nozaki_Nakaura_Fujima_2023, title={Fairness of artificial intelligence in healthcare: review and recommendations}, volume={42}, url={https://pubmed.ncbi.nlm.nih.gov/37540463/}, DOI={10.1007/s11604-023-01474-3}, number={1}, journal={Japanese Journal of Radiology}, author={Ueda, Daiju and Kakinuma, Taichi and Fujita, Shohei and Kamagata, Koji and Fushimi, Yasutaka and Ito, Rintaro and Matsui, Yusuke and Nozaki, Taiki and Nakaura, Takeshi and Fujima, Noriyuki and Tatsugami, Fuminari and Yanagawa, Masahiro and Hirata, Kenji and Yamada, Akira and Tsuboyama, Takahiro and Kawamura, Mariko and Fujioka, Tomoyuki and Naganawa, Shinji}, year={2023}, month=aug, pages={3-15}}

@article{mehrabiSurveyBiasFairness2021,
  title = {A {{Survey}} on {{Bias}} and {{Fairness}} in {{Machine Learning}}},
  author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  year = {2021},
  month = jul,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {6},
  pages = {115:1--115:35},
  issn = {0360-0300},
  doi = {10.1145/3457607},
  urldate = {2023-12-21},
  abstract = {With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
  keywords = {deep learning,Fairness and bias in artificial intelligence,machine learning,natural language processing,representation learning}
}

@book{hastieElementsStatisticalLearning2009,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {The {Elements} of {Statistical} {Learning}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-0-387-84857-0 978-0-387-84858-7},
	url = {http://link.springer.com/10.1007/978-0-387-84858-7},
	urldate = {2025-05-13},
	publisher = {Springer New York},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	year = {2009},
	doi = {10.1007/978-0-387-84858-7},
}


@article{Fazelpour_Danks_2021, title={Algorithmic bias: Senses, sources, solutions}, volume={16}, url={https://compass.onlinelibrary.wiley.com/doi/full/10.1111/phc3.12760}, DOI={10.1111/phc3.12760}, number={8}, journal={Philosophy Compass}, author={Fazelpour, Sina and Danks, David}, year={2021}, month=jun }


@misc{Gao_Chou_McCaw_Thurston_Varghese_Hong_Gronsbell_2024, title={What is Fair? Defining Fairness in Machine Learning for Health}, url={https://arxiv.org/abs/2406.09307}, journal={arXiv.org}, author={Gao, Jianhui and Chou, Benson and McCaw, Zachary R. and Thurston, Hilary and Varghese, Paul and Hong, Chuan and Gronsbell, Jessica}, year={2024}, month=jun }


@misc{Yfantidou_Constantinides_Spathis_Vakali_Quercia_Kawsar_2023, title={Beyond Accuracy: A Critical Review of Fairness in Machine Learning for mobile and Wearable computing}, url={https://arxiv.org/abs/2303.15585}, journal={arXiv.org}, author={Yfantidou, Sofia and Constantinides, Marios and Spathis, Dimitris and Vakali, Athena and Quercia, Daniele and Kawsar, Fahim}, year={2023}, month=mar }

@article{Castelnovo_Crupi_Greco_Regoli_Penco_Cosentini_2022, title={A clarification of the nuances in the fairness metrics landscape}, volume={12}, url={https://www.nature.com/articles/s41598-022-07939-1}, DOI={10.1038/s41598-022-07939-1}, number={1}, journal={Scientific Reports}, author={Castelnovo, Alessandro and Crupi, Riccardo and Greco, Greta and Regoli, Daniele and Penco, Ilaria Giuseppina and Cosentini, Andrea Claudio}, year={2022}, month=mar }



@inproceedings{Dwork_Hardt_Moritz_Pitassi_Toniann_Reingold_Omer_Zemel_Richard_2012,
author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
title = {Fairness through awareness},
year = {2012},
isbn = {9781450311151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090236.2090255},
doi = {10.1145/2090236.2090255},
abstract = {We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of "fair affirmative action," which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.},
booktitle = {Proceedings of the 3rd Innovations in Theoretical Computer Science Conference},
pages = {214-226},
numpages = {13},
location = {Cambridge, Massachusetts},
series = {ITCS '12}
}

@article{Anderson_Visweswaran_2024, title={Algorithmic individual fairness and healthcare: a scoping review}, volume={8}, url={https://academic.oup.com/jamiaopen/article/8/1/ooae149/7934945}, DOI={10.1093/jamiaopen/ooae149}, number={1}, journal={JAMIA Open}, author={Anderson, Joshua W and Visweswaran, Shyam}, year={2024}, month=dec }

@misc{Plecko_Bareinboim_2022, title={Causal Fairness analysis}, url={https://arxiv.org/abs/2207.11385}, journal={arXiv.org}, author={Plecko, Drago and Bareinboim, Elias}, year={2022}, month=jul }

@article{Makhlouf_Zhioua_Palamidessi_2024, title={When causality meets fairness: A survey}, volume={141}, url={https://www.sciencedirect.com/science/article/abs/pii/S2352220824000543}, DOI={10.1016/j.jlamp.2024.101000}, journal={Journal of Logical and Algebraic Methods in Programming}, author={Makhlouf, Karima and Zhioua, Sami and Palamidessi, Catuscia}, year={2024}, month=jun, pages={101000} }

@misc{Awasthi_Cortes_Mansour_Mohri_2020, title={Beyond individual and group fairness}, url={https://arxiv.org/abs/2008.09490}, journal={arXiv.org}, author={Awasthi, Pranjal and Cortes, Corinna and Mansour, Yishay and Mohri, Mehryar}, year={2020}, month=aug }

@article{Berk_Heidari_Jabbari_Kearns_Roth_2018, title={Fairness in Criminal Justice Risk Assessments: The State of the Art}, volume={50}, url={https://journals.sagepub.com/doi/10.1177/0049124118782533}, DOI={10.1177/0049124118782533}, number={1}, journal={Sociological Methods & Research}, author={Berk, Richard and Heidari, Hoda and Jabbari, Shahin and Kearns, Michael and Roth, Aaron}, year={2018}, month=jul, pages={3-44} }

@book{barocas2023fairness,
  title     = {Fairness and Machine Learning: Limitations and Opportunities},
  author    = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
  year      = {2023},
  publisher = {The MIT Press},
  address   = {Cambridge, Massachusetts},
  language  = {English}
}

@article{Berk_Heidari_Jabbari_Kearns_Roth_2018, title={Fairness in Criminal Justice Risk Assessments: the state of the art}, volume={50}, url={https://journals.sagepub.com/doi/10.1177/0049124118782533}, DOI={10.1177/0049124118782533}, number={1}, journal={Sociological Methods & Research}, author={Berk, Richard and Heidari, Hoda and Jabbari, Shahin and Kearns, Michael and Roth, Aaron}, year={2018}, month=jul, pages={3-44} }

@article{Castelnovo_Crupi_Greco_Regoli_Penco_Cosentini_2022, title={A clarification of the nuances in the fairness metrics landscape}, volume={12}, url={https://www.nature.com/articles/s41598-022-07939-1}, DOI={10.1038/s41598-022-07939-1}, number={1}, journal={Scientific Reports}, author={Castelnovo, Alessandro and Crupi, Riccardo and Greco, Greta and Regoli, Daniele and Penco, Ilaria Giuseppina and Cosentini, Andrea Claudio}, year={2022}, month=mar }

 @Manual{fairness_package,
    title = {fairness: Algorithmic Fairness Metrics},
    author = {Nikita Kozodoi and Tibor {V. Varga}},
    year = {2021},
    note = {R package version 1.2.1},
    url = {https://CRAN.R-project.org/package=fairness},
  }

  @misc{raffa2016clinical,
  author       = {Raffa, Jesse},
  title        = {Clinical data from the MIMIC-II database for a case study on indwelling arterial catheters (version 1.0)},
  year         = {2016},
  howpublished = {\url{https://doi.org/10.13026/C2NC7F}},
  note         = {PhysioNet},
  doi          = {10.13026/C2NC7F}
}

@incollection{raffa2016data,
  author    = {Raffa, Jesse D. and Ghassemi, Mohammad and Naumann, Tristan and Feng, Mengling and Hsu, Daniel J.},
  title     = {Data Analysis},
  booktitle = {Secondary Analysis of Electronic Health Records},
  year      = {2016},
  publisher = {Springer, Cham},
  pages     = {109--122},
  doi       = {10.1007/978-3-319-43742-2_9}
}

@article{goldberger2000physiobank,
  author    = {Goldberger, Ary L. and Amaral, Luis A. N. and Glass, Leon and Hausdorff, Jeffrey M. and Ivanov, Plamen Ch. and Mark, Roger G. and Mietus, Joseph E. and Moody, George B. and Peng, Chung-Kang and Stanley, H. Eugene},
  title     = {PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals},
  journal   = {Circulation [Online]},
  volume    = {101},
  number    = {23},
  pages     = {e215--e220},
  year      = {2000},
  url       = {https://doi.org/10.1161/01.CIR.101.23.e215},
  doi       = {10.1161/01.CIR.101.23.e215}
}

@article{wisniewski2022fairmodels,
  title     = {fairmodels: a Flexible Tool for Bias Detection, Visualization, and Mitigation in Binary Classification Models},
  author    = {Jakub Wiśniewski and Przemysław Biecek},
  journal   = {The R Journal},
  year      = {2022},
  volume    = {14},
  number    = {1},
  pages     = {227--243},
  doi       = {10.32614/RJ-2022-019},
  url       = {https://rj.urbanek.nz/articles/RJ-2022-019/}
}

@misc{mit_license,
      author = {Open Source Initiative},
      title = {The MIT license}, 
      url={https://opensource.org/license/mit}, 
      journal={Open Source Initiative} }


@Manual{
    devtools_package,
    title = {devtools: Tools to Make Developing R Packages Easier},
    author = {Hadley Wickham and Jim Hester and Winston Chang and Jennifer Bryan},
    year = {2022},
    note = {R package version 2.4.5},
    url = {https://CRAN.R-project.org/package=devtools},
  }